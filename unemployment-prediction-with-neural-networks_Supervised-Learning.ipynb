{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5151399031a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0mAnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultilayeredANNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput_data_len\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0mAnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5151399031a7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m           \u001b[0;31m#print (\"Loss: \\n\" + str(np.mean(np.square(self.out_data - self.matrix_feed_forward_nn(self.input_data)))) ) # mean sum squared loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m           \u001b[0;31m#print (\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_machine__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# this is to indicate that the machine is beign trained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5151399031a7>\u001b[0m in \u001b[0;36m__train_machine__\u001b[0;34m(self, input_data, out_data)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__train_machine__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mout_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_feed_forward_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this part will update the weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata_to_predcit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5151399031a7>\u001b[0m in \u001b[0;36mbackpropagation\u001b[0;34m(self, input_data, out_data, node_out_results)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnode_out_results\u001b[0m \u001b[0;31m# finds the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_deltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# appends all the output layer data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_out_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Dependencies for the network :\n",
    "    =====> neurolab\n",
    "    =====> matplotlib.pylab \n",
    "    =====> numpy \n",
    "Author : Ayodeji \n",
    "Date : 15-08-2018\n",
    "Project Objective:\n",
    "    This neural network model objective is to predict the future unemployment rate in Nigeria using neural Networks.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import neurolab as nln\n",
    "from sklearn.metrics  import accuracy_score\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "class MultilayeredANNet:\n",
    "    \n",
    "    def __init__(self , \n",
    "                 input_data , # This is the input data we will use to train our network and make predictions\n",
    "                 input_data_len ,\n",
    "                 out_data ,\n",
    "                 w1 = None ,\n",
    "                 w2 = None,\n",
    "                 verbose = False, # displays verbose messages \n",
    "                 debug = False,\n",
    "                 logging = False,\n",
    "                 log_file = \"\",\n",
    "                 epochs = None,  # time to train the network \n",
    "                 net_learning_rate = None # this is the learning rate of the neural network \n",
    "                ):\n",
    "        \"\"\"\n",
    "           Example : [2 ,34 ,43, 3] ----> input_data_len  = 4\n",
    "           \n",
    "           epochs : This is the number of times the machine will be trained to understand the patterns behind the datasets given to it\n",
    "           w1: This parameter is a string object that holds the FIRST weight of the network\n",
    "           w2: This parameter is a string object that holds the SECOND weight of the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # save the errors of the trained network\n",
    "        self.error_deltas = np.array([]) ; \n",
    "        \n",
    "        self.trained = False ; #this is set to false so that the machined is trained before calling predict() function\n",
    "        \n",
    "        self.input_data = X/np.amax(input_data, axis=0) # maximum of X array\n",
    "        self.input_data_len = input_data_len\n",
    "        \n",
    "        self.out_data = out_data / 100 ; # this is the output of the given input to help the machine train itself\n",
    "        self.output_data_len = 1 ; # this is the node length(size) of the output layer\n",
    "        \n",
    "        self.hidden_layer_node_len = 3 ;# the number of neuron the hidden layer will hold  \n",
    "        self.network_layers = 3\n",
    "                \n",
    "        self.biases = np.random.randint(0 , dtype=int , size=2 , high=2); #this are the biases that will addes to the Ann model\n",
    "       \n",
    "    \n",
    "        #down here we scale the data according to the the max value present in each array\n",
    "        \n",
    "        \n",
    "        #when the machine does not have a trained weight \n",
    "        #so a random new weight will be generated here\n",
    "        if w1 == None and w2 == None :\n",
    "            #since we have three layers for the neural network, then we are going to build the network with two weights arrays\n",
    "            #of hiddenlayer_node_lenght * input_data_len matrix \n",
    "            self.W1 = np.random.randn(self.input_data_len , self.hidden_layer_node_len ) #  input_data_len(row) * 15(column) \n",
    "            self.W2 = np.random.randn(self.hidden_layer_node_len , self.output_data_len) # 15(row) * output_data_len\n",
    "        \n",
    "        #this will run when the machine has a trained dataset it wants to use \n",
    "        else :\n",
    "            self.trained = True ; #this is automatically trained when the weight is supplied to the network\n",
    "            self.W1 = np.loadtxt(w1) # will load the first weight and assign it to W1\n",
    "            self.W2 = np.loadtxt(w2) # will load the second weight and assign it to w2\n",
    "        \n",
    "    def saveWeights(self):\n",
    "        np.savetxt(\"w1.txt\", self.W1, fmt=\"%s\")\n",
    "        np.savetxt(\"w2.txt\", self.W2, fmt=\"%s\")\n",
    "    \n",
    "    \n",
    "    #this below function is the activation function which is used for the switching \n",
    "    def activation_func(self , s):\n",
    "        \"\"\"\n",
    "        This function is used to trigger the switching when the ouput is greater than a certain threshold it\n",
    "        changes the value of the ouput 1, when it is lesser it value between ( 0 --> 1 or -1 ---> 1)\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-s))   \n",
    "    \n",
    "    def sigmoidPrime(self , s ):\n",
    "        #s----> is a numpy array object \n",
    "        return s * ( 1 - s)\n",
    "    \n",
    "    def matrix_feed_forward_nn(self , node_in):\n",
    "            self.z1 = self.input_data.dot(self.W1)# + self.biases[0]\n",
    "            self.z2 = self.activation_func(self.z1)  #finds the dot products of the weight and the input node and add the biases\n",
    "            self.z3 = self.z2.dot(self.W2) #+ self.biases[1];\n",
    "            \n",
    "            output = self.activation_func(self.z3)\n",
    "            #print(\"z========> \" , self.z3)\n",
    "            #print(\"Activation Function==>\" , self.activation_func(output))\n",
    "            \n",
    "            return output # returns the ouput of the result\n",
    "    \n",
    "    #This tain how the machine to be able to get the correct set of weight to predict any data giving to it\n",
    "    #The biases of the neural network is also trained. The biases is also known as THRESHOLDS\n",
    "    def __train_machine__(self , input_data ,out_data):\n",
    "        o = self.matrix_feed_forward_nn(input_data)\n",
    "        self.backpropagation(input_data , out_data , o) # this part will update the weight\n",
    "        \n",
    "    def predict(self , data_to_predcit):\n",
    "        #if the machine is not trained, no prediction will be performed on the data provided\n",
    "        if self.trained == False :\n",
    "            print(\"[ TRAIN_ERROR ] : The network is not trained...This network can not predict the result of the input data.\\n\"\n",
    "            +\"please train the network first and then call this function again.\")\n",
    "            return\n",
    "        else:\n",
    "            return self.matrix_feed_forward_nn(data_to_predcit)\n",
    "        \n",
    "    #This function will update the weight of the network so that the machine to learn and predict\n",
    "    def backpropagation(self , input_data , out_data  ,node_out_results):\n",
    "        \n",
    "        self.o_error = out_data - node_out_results # finds the error \n",
    "        \n",
    "        self.error_deltas.append(self.o_error) # appends all the output layer data\n",
    "        \n",
    "        self.o_delta = self.o_error * (self.sigmoidPrime(node_out_results))\n",
    "        \n",
    "        #the hidden layer(s) size is 1\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        \n",
    "        self.z2_delta = self.z2_error * (self.sigmoidPrime(self.z2))\n",
    "        \n",
    "        #This following statements will update the weights (synapses) of the network\n",
    "        self.W1 +=input_data.T.dot(self.z2_delta)# adjusting first set (hidden --> output) weights\n",
    "        \n",
    "        self.W2 +=self.z2.T.dot(self.o_delta)# adjusting second set (input --> hidden) weights\n",
    "        \n",
    "        #updating the biases of the network from here\n",
    "        #self.biases[0] += self.self.input_data.T.dot(z2_delta)\n",
    "        #self.biases[1] += self.z2.T.dot(o_delta)\n",
    "       \n",
    "    def train(self):\n",
    "        for i in range(1000):\n",
    "          #print(\"Initial Weight======> \\nW1 : %s\\nW2 : %s\" % (self.W1 , self.W2) )\n",
    "          #print(\"# \" + str(i) + \"\\n\")\n",
    "          #print (\"Input (scaled): \\n\" + str(self.input_data) )\n",
    "          #print (\"Actual Output: \\n\" + str(self.out_data) )\n",
    "          #print (\"Loss: \\n\" + str(np.mean(np.square(self.out_data - self.matrix_feed_forward_nn(self.input_data)))) ) # mean sum squared loss\n",
    "          #print (\"\\n\")\n",
    "          self.__train_machine__(self.input_data , self.out_data)\n",
    "        \n",
    "        # this is to indicate that the machine is beign trained\n",
    "        print (\"Predicted Output: \\n\" + str(self.matrix_feed_forward_nn(self.input_data)) )\n",
    "        self.trained = True ;\n",
    "    #this network train the data using Neurolab package \n",
    "    #It trains the network by supplying input and ouput data to the network\n",
    "    #The input data is the training set and while the ouput data is the target label\n",
    "    def train_nln(self, show_error_graph = None):\n",
    "        try :\n",
    "            self.nln_error_data = nln.train(input_data ,out_data) \n",
    "            #-------------------------------------TRAINIGN THE NETWORK MODEL---------------------------------------------------------\n",
    "            if show_error_graph:\n",
    "                plt.plto(self.nln_error_data) # plot the np array error data from the taining function model\n",
    "                plot.grid() # Shows a grid view when the errro_data is plotted\n",
    "                #after the training is done the model will save the weights of the neural network\n",
    "                nln.save(\"trained_unemployment_weights.txt\") # the trained weights are saved into the txt file\n",
    "            #---------------------------------ERROR HANDLING-----------------------------------------------\n",
    "            \n",
    "            def get_weight_and_biases():\n",
    "                self.weights = np.array([[]]); # @2Dim array object will be creted for the network weights\n",
    "                self.biases  = np.array([]); # 1Dim array object that will hold the biases of the neural network\n",
    "                self.wb_holder = nln.load(\"trained_unemployment_weights.txt\") #loads the neural network weights and biases\n",
    "                \n",
    "                #This iteration pushes the weights of the trained network and biases into the \n",
    "                # arrays created above ^\n",
    "                for layer_index in range(0, len(self.wb_holder.layers)):\n",
    "                    self.weights.append(self.wb_holder.layers[layer_index].np['w']) # appends the trained weights\n",
    "                    self.biases.append(self.wb_holder.layers[layer_index].np['b'])# appends the trained biases\n",
    "                    \n",
    "                \n",
    "        except Exception:\n",
    "            print(\"There is an argument ERROR_.\")\n",
    "        \n",
    "        \n",
    "\n",
    "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "        \n",
    "Ann = MultilayeredANNet(input_data= X , input_data_len= len(X[0]) , out_data= y)\n",
    "Ann.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
